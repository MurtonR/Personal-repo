Edge Detection:

Typically the first step in image processing is 'edge detection', to find all the edges in the image.

In machine vision and edge is defined as a curve in the image plane across which there is a significant change in brightness. Finding edges is about finding sharp changes in pixel brightness.

One way to find edges is to differentiate the image and then look for areas where the magnitude of the derivitive is large, is the derivitive is large then the difference in local brightness values are also large. This method does find edges, however it also finds shadows and noise.

Noise produces large sudden peaks that have no meaningful structure and as such can be removed by using a process called 'smoothing'.

In order to do 'smoothing' we apply a mathematical procedure calle 'convolution' which finds and removes the isolated peaks. It does this by applying  a filter to the data this is called 'convolving the image', the process of covolution involves using many filters with different orientations.

Once we have all the edges the next step is to find objects within the image. 'Segmentation; is the process that refers to dividing or organising the image into parts that correspond to the occurence of continous objects.



Model Based Vision:

Image when the robot does edge detection it produces what looks like a poor line drawing and compares that line drawing to stored drawings to see if any of them match, this way it could identify objects by shape alone.

These stored drawings are called 'models' and the process of using them is called model-based vision. 2D line drawings are simple however it does not mean the process is not complex as the robot may be viewing the object from any angle or distance, this in turn means that the robot needs to be able to scale and rotate the image in order to match objects to their line drawing counterparts. Additionally the robot does not know which of the models are close to the object and as such must look through them in turn with varying scales and angles. All of this is computationally intensive due to having to store all of these images and then to process them.

Models can range from simplistic 2D images to weirdly distored , combinations of various views from multiple angles of an object so that the object can be recognised mathematically from multiple angles at once.

Many very successful face recognition models use only a few images of the face and combine then using math to create a model that can recognise the face at various angles from one image.




Motion Vision:

More often than not the visual systems are on bodies that move and motion makes visual processing much more difficult. 

Motion vision is a set of machine vision approaches that use motion to facilitate visual processing. In order to identify static objects it can use its own motion, for example by looking at image at two consecutuive time stamps and moving the camera inbetween. We can subtract the images and we will get the 'movement' between the two while the objects stay the same.



Stereo Vision:

Many creatures in nature have two eyes, this allows them to have 'binocular vision'. The main advantage is havinig the ability to see in 'stereo', 'stereo vision' is the ability to use the combined points of view from two eyes or camera to recreate 3D objects and percieve depth.



Textures, Shading, Contours:

How smooth or rough a surface can help when it comes to recognising different objects and materials, for example sandpaper looks different to fur. These differences can be very useful and are helpful in visual processing, if an area has the same texture and similiar brightness we can assume they are part of the same surface/object.

Additionally the shading, contours and simple shape can also be used to help identify different parts of an image, all of which helps with visual processing.



Biological Vision:

Biological vision systems are poorly understood but are vastly better than artifical counterparts, for example humans use  model-based and motion vision that are both far better than way a computer is able to do.

One part of biological motion vision is the 'vestibular ocular reflex' (VOR) that allow us to move around while looking and have the result images not be a huge blur.



Robot Vision:

One of the biggest issues with robot vision that makes it more difficult than many other types of machine vision is that robot vision has any stict parameters that it must follow, for exmaple:

-If the robot has finished it's task

-If there any objects in the way

-If the robot is about to fall down some stairs

-If there is a human that must be tracked/avoided/help and more

-If the robot can see its task; moving a coloured ball, reaching a glowing charging station


It is also very difficult to check for all of these before the robot gets hit by a car or runs into a wall, luckily there are some methods that can be used that reduce the need for unnecessary processing.

Here are a few:

-Using colour; for example the red of a stop sign, the colour of skin, if a human is wearing a green vest 

-'Blob tracking' is done by using a combination colour and movement, this is done by marking important objects/people with salient (noticeable) colours. This allows the robot to identify the recognisable colour and movement without having to actually identify the object or person.

-Using a smaller image plane means the robot has to process less information and as such is able to make decisions based on that processing faster. However of course less information is in total gathered from the image plane, the effect this has can be reduced if we're clever and know what environment the robot will be working within.

-Combining faster, simplier sensors with vision in order to help focus the visual information the robot obtains. For example using IR sensors that are tuned to human body heat to help identify where a human is and from there use the visual sensors to try to identify the person. Grippers can be used to move objects so that visual sensors will have a clearer view of what they are identifying.

-Using knowledge about the environment and specifically looking for those objects/patterns. For example the white and yellow lines are used in robotic cars in order for them to follow roads effectively.