A robot like living creatures needs to be able to sense it's environment in order to survive and achieve set objectives.

It must also be able to sense the state of it's own body, this called the internal state in robots.

The amount of information a robot can sense greatly effects it's ability to react to changes in the environment, achieve goals and act intelligently.


There are two types of sensors a robot could have based on the information it is sensing:

-Proprioceptive sensors; senses the robot's internal state, for example the position of the wheels, the joint angles of the arms or the orientation of the endeffector. Propioceptive means 'one's own property', propioception is the sensing the state of one's own body, it is equally important in living creatures as in robotics.

-Exteroception; These sensors percieve the elements of the state of the external world around the world, foe example light intensity, distance to nearby objects/walls, sound, temperature of the environment. Exteroception is the process of sensing the world around the robot, this includes sensing the robot itself.


These two types of sensors make up the peceptual system of the robot, however the issue with the sensors on a robot is although they can sense the environment very well they cannot provide convienent state information about the environment.

An example of this is a sensor cannot tell you that there is a chair infront of the robot, or that there is a person sitting on it and is uncomfortable, it can tell you that there is an object of some kind and the colour of it, the light intensity, how loud the sound is and more, but not the specifics about what state the environment is in.


Sensors are physical devices that measure physical quantities, if a robot wants to understand at all what state the environment is in it needs to have a program that can determine, from the information the sensors have gathered, anything about the state of the environment, the sesors cannot do this themselves.



Uncertainty refers to the robots inability to be certain, to know for sure about it's state and the state on the environment, in order to take optimal actions at all times the uncertainty needs to be low.

Physical Property → Sensing Technology
Contact → bump, switch
Distance → ultrasound, radar, infra red
Light level → photocells, cameras
Sound level → microphones
Strain → strain gauges
Rotation → encoders and potentiometers
Acceleration → accelerometers and gyroscopes
Magnetism → compasses
Smell → chemical sensors
Temperature → thermal, infra red
Inclination → inclinometers, gyroscopes
Pressure → pressure gauges
Altitude → altimeter


Uncertainty can come in a variety of forms:

-Sensor noise and errors

-Sensor limitations

-Actuators and effectors noise and errors

-Hidden and partially observable states can cause the sensor to recieve incorrect information that has a high amount of uncertainty.

-A lack of previous knowledge about an environment, or a dynamic and changing environment.


Uncertainty exists because robots are physical mechanisms that operate in a physical world that is messy, noisy and challenging, combine this with errors and noise made by sensors, effectors and actuators.

The mnore information a sensor percieves the more processing is required in order for that information to be useful.


Simple sensors that provide simple information can be used almost directly, for example a mobile wheeled robot that has a switch that when the robot bumps into a wall is activated, when the switch is activated the robot stops, in this case there is a one to one connection between the sensor obtaining information from the environment and the robot acting upon this info.



There are two ways that sensory information can be treated.

-We can either ask "given the sensory information, what should the robot do", or "given the sensory information, what was the world like when this reading was taken".

Simple sensors can be used to answer the first question which is about action in the world, however simple sensors are unable to answer the first question. By using more complex sensors the information, although taking more time and energy to process, can be used to attempt to reconstruct the world that produced the reading. However sensors can only attempt to reconstruct the elements of the external environment that it percieves information about, for example the image from a camera could be used by looking for lines and colours or patterns that can be used to identify objects such as chairs or people.


Thwe process of going from the output of a sensor to an intelligent result is sometimes called the signal-to-symbol problem. This refers to the fact that sensors produce a signal when they recieve information from the environment, and this is used to make a decision involving symbols. For example a robot with a camera could be programmed that when it detects a man smiling it will stop, the signal is the camera image and the symbol would be the smile.

Signals must be processed before they can be used in order to extract the information the robot needs to identify symbols and information that is required in order for the robot to make the optimal decision. This is called sensor preprocessing as it occurs before any decisions are made.



Levels of processing:

One example of sensing would be measuring the voltage in order to determine if a switch is on or off for example.

Another example would be using signal processing in order to remove background noise from audio information obtained by a microphone and then comparing that isolated sound to one or more stored sounds in order to perform recognition.

Another example is a camera that needs to identify where a person is in a room, once the signal has been processed the robot will compare the visual data to a large database in order to identify the person, this is done with computation.

Computation is the slowest but most general method of processing, however it is possible to solve it a lower but faster level, for example vision chips are designed to process visual information only, and are capable of recognising faces, fruits, people and more. They are very fast but very specialised and as such they cannot be used to process any other types of information.


Perception in robots requires:

-Sensors (Power and electronics)

-Computation (Power and electronics)

-Connectors (to connect everything)



There are 4 main ways of effective perception.

-Action oriented perception; instead of attempting to reconstruct how the world was, the robot can use knowlege about the task to look for specific stimuli and then act upon that information, for example if the goal was to identify a person, you could make the specific stimuli the colour/pattern of their shirt, the shape of their face, the speed they move or the way they speak.

-Expectation based perception; use knowledge about the robots environment in order to guide and constrain how stimuli can be interpreted, for example a burglar alarms detect all movement as people even if it isn't because it is only designed for one purpose and the environment it is used in optimally would only contain burglars

-Task driven perception; direct perception where more information in needed, in this case the robot does not sense passively instead it actively turns it's body/sensors to where information seems most available. This is taken for granted in humans who reflexively turn their head to incoming sounds or light, allowing us to gather more information as the focus of our sensors is on the source of the information that is relevant.

-Perceptual classes; divide the world into classes into perpetual catagories that are useful for getting the job done and removing nexcess processing, for example a robot that can measure the distance from the nearest object in three classes instead of processing what to do for each different distance from the nearest object it could be simplified to ,too close, good for now but be alert, don't worry.


The idea that sensor function should influence the sensor form is common in nature and should be heavily relied upon in robotics in order to have robots that are optimal for their task and environment.



It is possible to combine the information from multiple sensors in order to get a clearer picture/ more info about the stimuli being detected. This is called sensor fusion.